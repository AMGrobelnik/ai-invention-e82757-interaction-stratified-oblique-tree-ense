{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISO-FIGS Benchmark — Breast Cancer Wisconsin Dataset\n",
    "\n",
    "**Interaction-Stratified Oblique FIGS** benchmark dataset preparation and exploration.\n",
    "\n",
    "This notebook loads and analyses the **Breast Cancer Wisconsin (Diagnostic)** dataset\n",
    "— the canonical FIGS benchmark with 30 highly-correlated features computed from\n",
    "cell-nuclei images. Strong within-group correlations (radius↔perimeter↔area, r > 0.99)\n",
    "make axis-aligned splits suboptimal and motivate the oblique splits central to ISO-FIGS.\n",
    "\n",
    "| Property | Value |\n",
    "|---|---|\n",
    "| Source | `sklearn.datasets.load_breast_cancer` |\n",
    "| Features | 30 (10 measurements × 3 statistics: mean, SE, worst) |\n",
    "| Task | Binary classification: 0 = malignant, 1 = benign |\n",
    "| Class balance | ~37 % malignant, ~63 % benign |\n",
    "| Full dataset | 200 examples (160 train + 40 test) |\n",
    "| Demo subset | 15 stratified examples |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 — Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nfrom collections import Counter\n\nimport numpy as np"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nGITHUB_RAW_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-e82757-interaction-stratified-oblique-tree-ense/main/all_output_files_verified_and_under_size_limits/demo/demo_data.json\"\nLOCAL_FILE = \"demo_data.json\"\n\n\ndef load_data():\n    \"\"\"Load demo data from GitHub (works in Colab) or local file (dev fallback).\"\"\"\n    # Try GitHub URL first (works in Colab)\n    try:\n        import urllib.request\n        with urllib.request.urlopen(GITHUB_RAW_URL) as response:\n            return json.loads(response.read().decode())\n    except Exception:\n        pass\n    # Fallback to local file\n    if os.path.exists(LOCAL_FILE):\n        with open(LOCAL_FILE) as f:\n            return json.load(f)\n    raise FileNotFoundError(\"Could not load data from GitHub or local file\")\n\n\ndata = load_data()\nexamples = data[\"examples\"]\nmetadata = data.get(\"metadata\", {})\nprint(f\"Loaded {len(examples)} demo examples\")\nif metadata:\n    print(f\"Dataset: {metadata.get('description', 'N/A')}\")\n    print(f\"Full dataset size: {metadata.get('total_in_full_dataset', '?')} examples\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 — Example Schema\n",
    "\n",
    "Each record contains:\n",
    "- **input** — natural-language prediction prompt with all 30 feature values\n",
    "- **context** — structured metadata (feature names & values, known interactions)\n",
    "- **output** — target label string (`\"0\"` = malignant, `\"1\"` = benign)\n",
    "- **dataset** / **split** — provenance fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = examples[0]\n",
    "print(\"Top-level keys:\", list(ex.keys()))\n",
    "print(f\"\\ndataset : {ex['dataset']}\")\n",
    "print(f\"split   : {ex['split']}\")\n",
    "label_name = 'malignant' if ex['output'] == '0' else 'benign'\n",
    "print(f\"output  : {ex['output']} ({label_name})\")\n",
    "print(f\"\\nContext keys: {list(ex['context'].keys())}\")\n",
    "ctx = ex['context']\n",
    "print(f\"  task_type       : {ctx['task_type']}\")\n",
    "print(f\"  n_features      : {ctx['n_features']}\")\n",
    "print(f\"  n_samples_total : {ctx['n_samples_total']}\")\n",
    "print(f\"  source          : {ctx['source']}\")\n",
    "print(f\"\\nInput prompt (first 200 chars):\")\n",
    "print(f\"  {ex['input'][:200]}\\u2026\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 — Split & Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = {\"0\": \"malignant\", \"1\": \"benign\"}\n",
    "\n",
    "split_cnt = Counter(e[\"split\"] for e in examples)\n",
    "print(\"Split distribution:\")\n",
    "for s in sorted(split_cnt):\n",
    "    print(f\"  {s:6s} : {split_cnt[s]}\")\n",
    "\n",
    "print(\"\\nPer-split class counts:\")\n",
    "for s in sorted(split_cnt):\n",
    "    cc = Counter(LABEL[e[\"output\"]] for e in examples if e[\"split\"] == s)\n",
    "    print(f\"  {s:6s} : {', '.join(f'{k}={v}' for k, v in sorted(cc.items()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 — Feature Matrix & Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = examples[0][\"context\"][\"feature_names\"]\n",
    "X = np.array([e[\"context\"][\"feature_values\"] for e in examples])\n",
    "y = np.array([int(e[\"output\"]) for e in examples])\n",
    "\n",
    "print(f\"X shape : {X.shape}   (samples \\u00d7 features)\")\n",
    "print(f\"y shape : {y.shape}\")\n",
    "print(f\"\\nFeature statistics (first 10 of {len(feature_names)}):\")\n",
    "print(f\"{'#':>3}  {'Feature':>28s}  {'Mean':>10s}  {'Std':>10s}  {'Min':>10s}  {'Max':>10s}\")\n",
    "print(\"-\" * 78)\n",
    "for i in range(min(10, X.shape[1])):\n",
    "    c = X[:, i]\n",
    "    print(f\"{i:3d}  {feature_names[i]:>28s}  {c.mean():10.4f}  {c.std():10.4f}  {c.min():10.4f}  {c.max():10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 — Feature Correlations (Motivating Oblique Splits)\n",
    "\n",
    "The strongest correlations occur within **size groups** (radius, perimeter, area)\n",
    "and across measurement tiers (mean ↔ worst). These highly-correlated feature\n",
    "groups make axis-aligned decision-tree splits suboptimal and directly motivate\n",
    "the oblique (multi-feature) splits used by ISO-FIGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_FEATS = [\n",
    "    \"mean radius\", \"mean perimeter\", \"mean area\",\n",
    "    \"worst radius\", \"worst perimeter\", \"worst area\",\n",
    "    \"mean concavity\", \"mean concave points\",\n",
    "]\n",
    "kidx = [feature_names.index(f) for f in KEY_FEATS]\n",
    "C = np.corrcoef(X[:, kidx].T)\n",
    "\n",
    "short = [f[:9] for f in KEY_FEATS]\n",
    "print(\" \" * 11 + \"\".join(f\"{s:>10s}\" for s in short))\n",
    "for i, s in enumerate(short):\n",
    "    print(f\"{s:>10s} \" + \"\".join(f\"{C[i,j]:10.3f}\" for j in range(len(short))))\n",
    "\n",
    "print(\"\\nHighly correlated pairs (|r| > 0.93):\")\n",
    "for i in range(len(KEY_FEATS)):\n",
    "    for j in range(i + 1, len(KEY_FEATS)):\n",
    "        if abs(C[i, j]) > 0.93:\n",
    "            print(f\"  {KEY_FEATS[i]} \\u2194 {KEY_FEATS[j]} : r = {C[i,j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 — Known Interaction Structure\n",
    "\n",
    "The dataset metadata documents the feature interactions that ISO-FIGS leverages\n",
    "for its interaction-stratified tier construction and ANOVA decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = examples[0][\"context\"].get(\"known_interactions\", \"(none)\")\n",
    "print(\"Known feature interactions (from context metadata):\\n\")\n",
    "for part in interactions.split(\", \"):\n",
    "    print(f\"  \\u2022 {part.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 — Class Separation by Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP = [\"mean radius\", \"mean area\", \"mean concavity\",\n",
    "       \"worst radius\", \"worst area\", \"worst concavity\"]\n",
    "\n",
    "print(f\"{'Feature':>25s}  {'Malignant':>10s}  {'Benign':>10s}  {'Ratio':>7s}\")\n",
    "print(\"-\" * 58)\n",
    "for fname in SEP:\n",
    "    fi = feature_names.index(fname)\n",
    "    m = X[y == 0, fi].mean()\n",
    "    b = X[y == 1, fi].mean()\n",
    "    r = m / b if b else float('inf')\n",
    "    print(f\"{fname:>25s}  {m:10.4f}  {b:10.4f}  {r:6.2f}x\")\n",
    "\n",
    "print(\"\\n\\u2192 Malignant tumours show systematically larger size and concavity.\")\n",
    "print(\"  These correlated feature groups motivate oblique (multi-feature) splits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 — Reproducing the Full Dataset\n",
    "\n",
    "This demo notebook uses **15 stratified examples** for quick exploration.\n",
    "To regenerate the full 200-example benchmark dataset:\n",
    "\n",
    "```bash\n",
    "pip install numpy scikit-learn\n",
    "python data.py   # → full_data_out.json (200 examples, ~580 KB)\n",
    "```\n",
    "\n",
    "The pipeline is fully deterministic (`RANDOM_SEED = 42`) and relies only on\n",
    "`sklearn.datasets.load_breast_cancer` — no external data downloads required."
   ]
  }
 ]
}